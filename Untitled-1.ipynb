{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloders\n",
    "\n",
    "\"\"\"\n",
    "model, criterion, optimizer, data_transforms_train = make2(config)\n",
    "data_path = \"C:/Users/Joan/Desktop/Deep_Learning_project/features/data/ImageSets/0\"\n",
    "img_dir = \"C:/Users/Joan/Desktop/Deep_Learning_project/features/data/JPEGImages\"\n",
    "anotation_path= r\"C:\\Users\\Joan\\Desktop\\Deep_Learning_project\\dlnn-project_ia-group_15\\anotations.pkl\"\n",
    "train_img_names, y_train, test_img_names, y_test, val_img_names, y_val = load_labels_and_split(data_path)\n",
    "ocr_data = pd.read_pickle(anotation_path)\n",
    "train_dataset = Dataset_ConText(img_dir, train_img_names, y_train, ocr_data, transform=data_transforms_train)\n",
    "train_loader = make_loader(train_dataset, config.batch_size)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "\"\"\"\n",
    "def make(config, train=True, device=\"cuda\"):\n",
    "    # Make the data and model\n",
    "    data_path = \"C:/Users/Joan/Desktop/Deep_Learning_project/features/data/\"\n",
    "    anotation_path= r\"C:\\Users\\Joan\\Desktop\\Deep_Learning_project\\dlnn-project_ia-group_15\\anotations.pkl\"\n",
    "    input_size = 256\n",
    "    if train:\n",
    "        data_transforms_train = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomResizedCrop(input_size),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        train_df, val_df = make_dataframe(data_path, anotation_path, train=train)\n",
    "        train_dataset = Dataset_ConText(train_df, data_transforms_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "        val_dataset = Dataset_ConText(val_df, data_transforms_train)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "        # Make the model\n",
    "        model = ConTextTransformer(num_classes=config.classes, channels=3, dim=256, depth=2, heads=4, mlp_dim=512).to(device)\n",
    "\n",
    "        # Make the loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        return model, train_loader, val_loader, criterion, optimizer\n",
    "    else:\n",
    "        data_transforms_test = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(input_size),\n",
    "            torchvision.transforms.CenterCrop(input_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        test_df = make_dataframe(data_path, anotation_path, train=train)\n",
    "        test_dataset = Dataset_ConText(test_df, data_transforms_train)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "        return  test_loader\n",
    "\n",
    "# Adds the columns of two dataframes\n",
    "def merge_data(imagesAndLabels, ocr_data):\n",
    "    data = pd.concat([imagesAndLabels, ocr_data], axis=1, join=\"inner\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# Call this function to get the dataframes of the data, if train is True, it will return the train and validation dataframes,\n",
    "#  if not, it will return the test dataframe\n",
    "def make_dataframe(data_dir, anotation_path, train=True):\n",
    "    sets_dir = data_dir + \"/ImageSets/0\"\n",
    "    train_img_names, y_train, test_img_names, y_test, val_img_names, y_val = load_labels_and_split(sets_dir)\n",
    "    ocr_data = pd.read_pickle(anotation_path)\n",
    "    if train:\n",
    "        train_data = load_images(train_img_names, y_train, data_dir)\n",
    "        val_data = load_images(val_img_names, y_val, data_dir)\n",
    "        train_data = merge_data(train_data, ocr_data)\n",
    "        val_data = merge_data(val_data, ocr_data)\n",
    "        return train_data.iloc[:int(len(train_data.index)/2), :], val_data\n",
    "    else:\n",
    "        test_data = load_images(test_img_names, y_test, data_dir)\n",
    "        test_data = merge_data(test_data, ocr_data)\n",
    "        return test_data\n",
    "\n",
    "\n",
    "# Loads the images and creates a dataframe with the correpondent labels\n",
    "def load_images(img_names, labels, data_dir):\n",
    "    img_dir = data_dir + \"JPEGImages\"\n",
    "\n",
    "    list_img = []\n",
    "    for img_name in img_names:\n",
    "        img = Image.open(os.path.join(img_dir, img_name)).convert('RGB')\n",
    "        list_img.append(torch.tensor(img, dtype=torch.ByteTensor).repeat(3, 1, 1))\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data[\"img\"] = list_img\n",
    "    data[\"label\"] = labels\n",
    "    data[\"name\"] = img_names\n",
    "    data.set_index(\"name\", inplace=True)\n",
    "    data[\"label\"] = data[\"label\"].astype(int)\n",
    "\n",
    "    return data\n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
