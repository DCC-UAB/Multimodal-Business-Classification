{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f23986a",
   "metadata": {},
   "source": [
    "### Loading the weights of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"/home/xnmaster/Project/model_MobileNet_V3.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd51c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import *\n",
    "from utils.utils import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = dict(\n",
    "        epochs=35,\n",
    "        classes=28,\n",
    "        batch_size=150,\n",
    "        batch_size_val_test=25,\n",
    "        learning_rate=0.00005,\n",
    "        patience=10,\n",
    "        dataset=\"ConText\",\n",
    "        architecture=\"Transformer\")\n",
    "\n",
    "model, train_loader, test_loader, val_loader = make_test(config)\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(model, test_loader):\n",
    "    model.eval()\n",
    "    # model.train()\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for labels, img, text, text_mask in test_loader:\n",
    "            img, labels, text, text_mask = img.to(device), labels.to(device), text.to(device), text_mask.to(device)\n",
    "            outputs = model(img, text, text_mask)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test images: {correct / total:%}\")\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34df6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_acc(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c008e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred(model, loader):\n",
    "    model.eval()\n",
    "    # model.train()\n",
    "    real = []\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for labels, img, text, text_mask in loader:\n",
    "            img, labels, text, text_mask = img.to(device), labels.to(device), text.to(device), text_mask.to(device)\n",
    "            outputs = model(img, text, text_mask)\n",
    "            pred.extend((outputs.data.max(1, keepdim=True)[1]).tolist())\n",
    "            real.extend(labels.tolist())\n",
    "    return real, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred = get_y_pred(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Credit: https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "def make_confusion_matrix(cf, group_names=None, categories='auto', count=False, percent=False, cbar=True, xyticks=True, xyplotlabels=True, sum_stats=True, figsize=None, cmap='Blues', title=None):\n",
    "    \n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class = {1: \"Bakery\",\n",
    "10:\"Dry Cleaner\",\n",
    "11:\"Funeral\",\n",
    "12:\"Hotspot\",\n",
    "13:\"MassageCenter\",\n",
    "14:\"MedicalCenter\",\n",
    "15:\"PackingStore\",\n",
    "16:\"Pawnshop\",\n",
    "17:\"PetShop\",\n",
    "18:\"Pharmacy\",\n",
    "19:\"Pizzeria\",\n",
    "2:\"Barber\",\n",
    "20:\"RepairShop\",\n",
    "21:\"Restaurant\",\n",
    "22:\"School\",\n",
    "23:\"SteakHouse\",\n",
    "24:\"Tavern\",\n",
    "25:\"TeaHouse\",\n",
    "26:\"Theatre\",\n",
    "27:\"Tobacco\",\n",
    "28:\"Motel\",\n",
    "3:\"Bistro\",\n",
    "4:\"Bookstore\",\n",
    "5:\"Cafe\",\n",
    "6:\"ComputerStore\",\n",
    "7:\"CountryStore\",\n",
    "8:\"Diner\",\n",
    "9:\"DiscounHouse\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "categories = [label2class[i] for i in range(1, 29)]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "make_confusion_matrix(cm, cmap='Blues', categories=categories, figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_recalls = {}\n",
    "for i in range(cm.shape[0]):\n",
    "    row = cm[i, :]\n",
    "    well_predicted = cm[i, i]\n",
    "    if sum(row) != 0:\n",
    "        recall = well_predicted/sum(row)\n",
    "        dict_recalls[label2class[i+1]] = recall\n",
    "    else:\n",
    "        dict_recalls[label2class[i+1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead09faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(dict_recalls)), [v for k,v in dict_recalls.items()])\n",
    "plt.xticks(range(len(dict_recalls)), [k for k,v in dict_recalls.items()],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall per class')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_precisions = {}\n",
    "for i in range(cm.shape[0]):\n",
    "    column = cm[:, i]\n",
    "    well_predicted = cm[i, i]\n",
    "    if sum(column) != 0:\n",
    "        precision = well_predicted/sum(column)\n",
    "        dict_precisions[label2class[i+1]] = precision\n",
    "    else:\n",
    "        dict_precisions[label2class[i+1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(dict_precisions)), [v for k,v in dict_precisions.items()])\n",
    "plt.xticks(range(len(dict_precisions)), [k for k,v in dict_precisions.items()],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision per class')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f1_scores = {}\n",
    "for k in dict_precisions.keys():\n",
    "    dict_f1_scores[k] = (2*dict_precisions[k]*dict_recalls[k])/(dict_precisions[k]+dict_recalls[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(dict_f1_scores)), [v for k,v in dict_f1_scores.items()])\n",
    "plt.xticks(range(len(dict_f1_scores)), [k for k,v in dict_f1_scores.items()],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 score per class')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean precision:\", np.mean([v for v in dict_precisions.values()]))\n",
    "print(\"Mean recall:\", np.mean([v for v in dict_recalls.values()]))\n",
    "print(\"Mean F1 score:\", np.mean([v for v in dict_f1_scores.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot where for each class we have the rpecision and recall in the same bar and the f1 score as a line\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.bar(range(len(dict_precisions)), [v for k,v in dict_precisions.items()], label=\"Precision\")\n",
    "plt.bar(range(len(dict_recalls)), [v for k,v in dict_recalls.items()], label=\"Recall\")\n",
    "\n",
    "plt.plot(range(len(dict_f1_scores)), [v for k,v in dict_f1_scores.items()], label=\"F1 Score\", color=\"red\")\n",
    "plt.xticks(range(len(dict_precisions)), [k for k,v in dict_precisions.items()],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Scores per class')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_normalize(images):\n",
    "  t = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "                           std=[1/0.229, 1/0.224, 1/0.255])\n",
    "  \n",
    "  return t(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a815ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_dataset = len(test_loader.dataset)\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1) \n",
    "\n",
    "    idx = np.random.randint(0, lenght_dataset)\n",
    "    label, img, txt, txt_mask = test_loader.dataset[idx]\n",
    "    img = img.unsqueeze(0)\n",
    "    txt = torch.tensor(txt).unsqueeze(0)\n",
    "    txt_mask = torch.tensor(txt_mask).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(img.to(device), txt.to(device), txt_mask.to(device))\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    if pred == label:\n",
    "      color = 'green'\n",
    "    else:\n",
    "      color = \"red\"\n",
    "\n",
    "    plt.title(\"Predicted: \"+ str(label2class[int(pred.to(\"cpu\").numpy())+1]), color=color)\n",
    "    plt.text(0.5, 1.1, \"Correct: \"+ str(label2class[label+1]), color=\"black\", fontsize=10, ha='center', va='bottom', transform=plt.gca().transAxes)\n",
    "\n",
    "    img = img.reshape(3, 224, 224)\n",
    "    img = de_normalize(img)\n",
    "    img = img.permute(1, 2, 0).numpy() \n",
    "    img -= img.min()\n",
    "    img = (img / img.max()) * 255\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, lenght_dataset)\n",
    "label, img, txt, txt_mask = test_loader.dataset[idx]\n",
    "img = img.unsqueeze(0)\n",
    "txt = torch.tensor(txt).unsqueeze(0)\n",
    "txt_mask = torch.tensor(txt_mask).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    output = model(img.to(device), txt.to(device), txt_mask.to(device))\n",
    "    prob, pred = torch.max(torch.nn.functional.softmax(output, dim=1), 1)\n",
    "\n",
    "if pred == label:\n",
    "    color = 'green'\n",
    "else:\n",
    "    color = \"red\"\n",
    "\n",
    "prob = prob.to(\"cpu\").numpy()[0]\n",
    "prob = round(prob*100, 1)\n",
    "plt.title(\"Predicted: \"+ str(label2class[int(pred.to(\"cpu\").numpy())+1]), color=color)\n",
    "plt.text(0.5, 1.1, \"Correct: \"+ str(label2class[label+1]), color=\"black\", fontsize=10, ha='center', va='bottom', transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "img = img.reshape(3, 224, 224)\n",
    "img = de_normalize(img)\n",
    "img = img.permute(1, 2, 0).numpy() \n",
    "img -= img.min()\n",
    "img = (img / img.max()) * 255\n",
    "plt.imshow(img.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp = [i[0] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot of false negative from the worse class in terms of recall\n",
    "class_to_show = \"DiscounHouse\"\n",
    "num_class_to_show = [k for k,v in label2class.items() if v == class_to_show][0] - 1\n",
    "\n",
    "index = []\n",
    "for i in len(y_pred_temp):\n",
    "    if y_pred_temp[i] != num_class_to_show and y_test[i] == num_class_to_show:\n",
    "        index.append(i) \n",
    "\n",
    "num_imgs_to_show = 20\n",
    "fig, ax = plt.subplots(4, 5, figsize=(12, 10))\n",
    "fig.suptitle(\"False negatives from the class: \" + class_to_show)\n",
    "\n",
    "import random \n",
    "for i in range(num_imgs_to_show):\n",
    "    random_index = random.choice(index)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "\n",
    "    label, img, txt, txt_mask = test_loader.dataset[random_index]\n",
    "    img = img.reshape(3, 224, 224)\n",
    "    img = de_normalize(img)\n",
    "    img = img.permute(1, 2, 0).numpy() \n",
    "    img -= img.min()\n",
    "    img = (img / img.max()) * 255\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37722cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = []\n",
    "for i in index:\n",
    "    y_pred_class.append(y_pred_temp[i])\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.hist(y_pred_class, bins=28)\n",
    "plt.xticks(range(28), [label2class[i+1] for i in range(28)],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of predictions')\n",
    "plt.title('Distribution of false negative of the class: ' + class_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b58e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in len(y_pred_temp):\n",
    "    if y_test[i] == num_class_to_show:\n",
    "        index.append(i)\n",
    "\n",
    "y_pred_class = []\n",
    "for i in index:\n",
    "    y_pred_class.append(y_pred_temp[i])\n",
    "\n",
    "#plot a histogram of the predictions of the class\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.hist(y_pred_class, bins=28)\n",
    "plt.xticks(range(28), [label2class[i+1] for i in range(28)],rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of predictions')\n",
    "plt.title('Predictions of the class: ' + class_to_show)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
